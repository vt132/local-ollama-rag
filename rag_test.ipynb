{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_experimental.llms.ollama_functions import ChatOllama\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings, HuggingFaceBgeEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\.conda\\envs\\ml-env\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = ChatOllama(model=\"mistral:instruct\", temperature=0)\n",
    "# For retrieval\n",
    "# embeddings = OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True,temperature=0.5, query_instruction=\"search_query:\", embed_instruction=\"search_document:\")\n",
    "\n",
    "# For creating vector db or fast retrieval\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"nomic-ai/nomic-embed-text-v1.5\",\n",
    "    model_kwargs={\n",
    "        'device': 'cuda',\n",
    "        'trust_remote_code':True,\n",
    "    },\n",
    "    encode_kwargs={'normalize_embeddings': True},\n",
    "    query_instruction = \"search_query:\",\n",
    "    embed_instruction = \"search_document:\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m loader \u001b[38;5;241m=\u001b[39m DirectoryLoader(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m\"\u001b[39m, glob\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m,use_multithreading\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2500\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, add_start_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m docs_chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(docs)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\ml-env\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:117\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load documents.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\ml-env\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:177\u001b[0m, in \u001b[0;36mDirectoryLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[0;32m    169\u001b[0m     futures\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    170\u001b[0m         executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_load_file_to_non_generator(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_load_file),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m         )\n\u001b[0;32m    176\u001b[0m     )\n\u001b[1;32m--> 177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures):\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult():\n\u001b[0;32m    179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m item\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\ml-env\\lib\\concurrent\\futures\\_base.py:245\u001b[0m, in \u001b[0;36mas_completed\u001b[1;34m(fs, timeout)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[0;32m    242\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[0;32m    243\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[1;32m--> 245\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n\u001b[0;32m    248\u001b[0m     finished \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39mfinished_futures\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\ml-env\\lib\\threading.py:581\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    579\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 581\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\.conda\\envs\\ml-env\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(path=\"Data\", glob=\"*.txt\",use_multithreading=True)\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2500, chunk_overlap=200, add_start_index=True)\n",
    "docs_chunks = text_splitter.split_documents(docs)\n",
    "db = Chroma.from_documents(docs_chunks, embeddings, persist_directory=\"./sentence_chroma_db\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc\n",
    "db = Chroma(persist_directory=\"./sentence_chroma_db\", embedding_function=embeddings, collection_metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shinkansen\n",
      "\n",
      "link: https://simple.wikipedia.org/wiki/Shinkansen\n",
      "\n",
      "The Shinkansen (Japanese: 新幹線, pronounced [ɕiŋkaꜜɰ̃seɴ], lit. ''new main line'') is a group of high-speed rail lines in Japan, upon which the famous \"Bullet Trains\" run. It is the world's first high-speed rail. The Shinkansen are run by the many JR companies. In the past, Japan Railway was called Japanese National Railways. It is now one group of private companies. JR also runs commuter trains and inter-city trains around Tokyo. The name \"Bullet Train\" is the English translation of the Japanese word dangan ressha (弾丸列車), which was the name given to the project while it was being studied in the 1940s. Nowadays, the trains are called Shinkansen trains. The name Shinkansen means \"New Trunk Line\". The trains are called \"Super Expresses\". Japan was the first country to build railway lines for high-speed travel. Because Japan has many mountains, the network that already existed was made of 3'6\" gauge (1067 mm) narrow gauge lines, which tended to take non-direct routes and could not be adapted to higher speeds. Because of this, Japan had a greater need for new high-speed lines than countries where the existing standard gauge or broad gauge rail system could be upgraded easily. Unlike the older lines, Shinkansen lines are standard gauge, and use tunnels and viaducts to go through and over obstacles, rather than around them. Construction of the first section of the Tokaido Shinkansen between Tokyo and Osaka started in 1959.\n"
     ]
    }
   ],
   "source": [
    "# test vector db\n",
    "query = \"Tell me about Elden Ring\"\n",
    "docs = db.similarity_search(query, k=2)\n",
    "\n",
    "# print results\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt for model\n",
    "if llm.model.find(\"mistral\") >= 0:\n",
    "    prompt  = PromptTemplate.from_template(\n",
    "\"\"\"[INST]\n",
    "You are an assistant. You will be provided the context relevant to the user's question and output the answer to the user.\n",
    "If the retrieved context was not relevant at all to the question, answer the question with your knowledge, say sorry to the user when you can not find the answer.\n",
    "You can also add some information if you know something about it, as long as your knowledge is relevant to the context. \n",
    "context: {context}\n",
    "question: {question}[/INST]\n",
    "\"\"\"\n",
    "    )\n",
    "    qa_chain = prompt | llm\n",
    "elif llm.model.find(\"phi3\") >= 0:\n",
    "    prompt  = PromptTemplate.from_template(\n",
    "\"\"\"<|user|>\n",
    "You are an assistant. You will be provided the context relevant to the user's question and output the answer to the user.\n",
    "If the retrieved context was not relevant at all to the question, answer the question with your knowledge, say sorry to the user when you can not find the answer.\n",
    "You can also add some information if you know something about it, as long as your knowledge is relevant to the context. \n",
    "context: {context}\n",
    "question: {question} <|end|> <|assistant|>\n",
    "\"\"\"\n",
    "    )\n",
    "    qa_chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Elden Ring', 'WORK_OF_ART'), ('From Software', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "# test spAcy NER \n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "query = \"Tell me about that new game Elden Ring by From Software\"\n",
    "nlp_object = nlp(query)\n",
    "print([(y.text, y.label_) for y in nlp_object.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def where_document_query(nlp_object_ents: list):\n",
    "    if len(nlp_object_ents) == 1:\n",
    "        return  {\"$contains\": nlp_object_ents[0].text}\n",
    "    if len(nlp_object_ents) > 1: \n",
    "        return {\"$or\": [{\"$contains\": ent.text} for ent in nlp_object_ents]}\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistral:instruct'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='39th G8 summit\\n\\nlink: https://simple.wikipedia.org/wiki/39th_G8_summit\\n\\nThe 39th G8 summit took place in Northern Ireland on 17th and 18th June 2013. The meeting was at the Lough Erne Golf Resort in Enniskillen,  Northern Ireland In the Queen\\'s speech at the state opening of Parliament in 2012, Elizabeth II said that \"my government will use this opportunity to promote international security and prosperity. \"[1] The gathering of the Group of Eight (G8) will be the 39th meeting in a series which began in 1976. [2] Previous G8 summits have been hosted by the United Kingdom at London (1977, 1984, 1991) and Birmingham (1998) in England. The 2005 summit was in Scotland at Gleneagles. [3] The G8 and the summit are part of a consultation process. The G8 is not an international organization. [4] It is an informal group. [5] The participants will be the \"core members\" of the group:[6] A number of national leaders are traditionally invited to attend the summit. They are asked to participate in some, but not all, G8 summit activities. The summit meetings are intended as a way to resolve differences among the G8 members. [7] Traditionally, the host country sets the agenda. [8]  As host, Prime Minister Cameron is expected to try to change the G8. He has criticised costs and questioned the value of G8 meetings. [9] Discussions at the 39th G8 summit will include some issues which remain unresolved from previous summits.\\n\\n[10] The G8 discussions will be about a range of topics, including Because of the nature of the summit, protest groups and other activists usually attend. The planning for the summit includes how to deal with these groups. [12] Britain\\'s leading aid groups and charities are planning a \"propaganda offensive\" which hopes to affect the food-dominated agenda for the G8. [11]', metadata={'source': 'Data\\\\39th G8 summit.txt', 'start_index': 0}),\n",
       " Document(page_content='38th G8 summit\\n\\nlink: https://simple.wikipedia.org/wiki/38th_G8_summit\\n\\nThe 38th G8 summit was held at Camp David, Maryland in the United States on May 18-19, 2012. [1]  The summit venue was moved from Chicago to rural Maryland in March 2012. [2] The Camp David summit of the Group of Eight (G8) was the 38th meeting in a series which began in 1976. [3] Previous G8 summits have been hosted by the United States at San Juan, Puerto Rico (1976); Williamsburg, Virginia (1983); Houston, Texas, Denver, Colorado (1997) and Sea Island, Georgia. [4] The G8 and the summit are part of a consultation process. The G8 is not an international organization. [5] It is an informal group. [6] The participants were the \"core members\" of the group:[7] A number of national leaders are traditionally invited to attend the summit. They are asked to participate in some, but not all, G8 summit activities. The leaders of four African nations were invited by the US president: The G8 leaders talked about making progress towards food security in Africa. [15] Others were invited, including: The summit is intended as a venue for resolving differences among the G8 members. [17] Traditionally, the host country of the G8 summit sets the agenda. [18] Discussions at the 38th G8 summit included some issues from previous summits. [19] The G8 discussions included a range of topics, including Planners anticipated protest groups and other activists.\\n\\n[22] When the venue for the summit was changed from Chicago, a White House spokesman said security and the possibility of protests were not factors in the decision. [23]  Some protest groups took credit for the change of venue. [24] For some, the G8 summit was a profit-generating event; as for example, the G8 Summit magazines which have been published since 1998. [25] Local businesses near Camp David are expecting more people in the area and profits because of the summit. [26] Media related to 38th G8 summit at Wikimedia Commons', metadata={'source': 'Data\\\\38th G8 summit.txt', 'start_index': 0}),\n",
       " Document(page_content='37th G8 summit\\n\\nlink: https://simple.wikipedia.org/wiki/37th_G8_summit\\n\\nThe 37th G8 summit was held 26–27 May 2011 in the commune of Deauville in France. [1] The Deauville summit of the Group of Eight (G8) was the 37th meeting in a series which began in 1976. Previous G8 summits have been hosted by France at Rambouillet (1975); Versailles (1982); Paris (1989); Lyon (1996);  and Évian-les-Bains (2003). [2] The G8 and the summit are part of a consultation process. The G8 is not an international organization. [3] It is an informal group. [4] These summit participants were the current \"core members\" of the G8:[5] Other national leaders are traditionally invited to attend the summit. [2]  They participate in some, but not all, G8 summit activities. African leaders who came to Deauville included: Also invited were: Traditionally, the host country of the G8 summit sets the agenda. French general priorities included peace and security. [15] Discussions included some issues which remained unresolved from previous summits. [16] Some of the specific topics on the agenda were: World events caused the list of topics to grow, including Protest groups and others organized public events. [28] In these demonstrations, the slogan G8 dégage (\"G8 Go Away\") was notable. [29] The demonstrators are widely understood to be against globalisation. [29] According to the Mayor of Deauville, \"Our main interest is the economic implications. \"[30] For some, the G8 summit became a profit-generating event.\\n\\nFor example, the G8 Summit magazines have been published under the auspices of the host nations for distribution to all attendees since 1998. [31] Media related to 37th G8 summit at Wikimedia Commons', metadata={'source': 'Data\\\\37th G8 summit.txt', 'start_index': 0})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Tell me about 39th G8 summit\"\n",
    "nlp_object = nlp(query)\n",
    "db.similarity_search(\n",
    "    query,\n",
    "    k=3,\n",
    "    where_document=where_document_query(nlp_object.ents)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' The 40th G7 summit was held in Brussels, Belgium on June 4-5, 2014. '\n",
      " 'Originally planned to be held at Sochi, Russia, the summit was moved due to '\n",
      " \"Russia's involvement in the 2014 Crimean crisis. As a result, Russia was not \"\n",
      " 'invited to participate. The core members of the G7 who attended were Canada, '\n",
      " 'the European Commission, France, Germany, Italy, Japan, and the United '\n",
      " 'Kingdom.\\n'\n",
      " '\\n'\n",
      " 'At the summit, the leaders of the G7 nations issued a joint statement '\n",
      " 'condemning Moscow for its \"continuing violation\" of Ukraine\\'s sovereignty '\n",
      " 'and announced their preparedness to impose further sanctions on Russia over '\n",
      " 'its actions in Ukraine. The summit was the first since Russia was expelled '\n",
      " 'from the group following its annexation of Crimea in March.\\n'\n",
      " '\\n'\n",
      " 'Planning for the summit had to anticipate protest groups and other '\n",
      " 'activists, and some saw it as a profit-generating event, such as the G8 '\n",
      " 'Summit magazines which have been published since 1998. The 40th G7 summit '\n",
      " 'was also the first since the establishment of the G20 in 1999, which '\n",
      " 'includes both the G7 countries and other major economies.')\n"
     ]
    }
   ],
   "source": [
    "# main flow\n",
    "import pprint\n",
    "\n",
    "query = \"Tell me about 40th G7 summit\"\n",
    "nlp_object = nlp(query)\n",
    "\n",
    "pprint.pprint(\n",
    "    qa_chain.invoke({\n",
    "        \"question\": query,\n",
    "        \"context\": \"/n\".join(\n",
    "            result.page_content for result in db.similarity_search(\n",
    "                query,\n",
    "                k=3,\n",
    "                where_document=where_document_query(nlp_object.ents)\n",
    "            )\n",
    "        ),\n",
    "    }).content\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db._collection_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
